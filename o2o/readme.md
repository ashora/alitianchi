## 赛题回顾
[本赛题](https://tianchi.aliyun.com/getStart/introduction.htm?spm=5176.100068.5678.1.357778d0VMd2XL&raceId=231593)提供用户在2016年1月1日至2016年6月30日之间真实线上线下消费行为，预测用户在2016年7月领取优惠券后15天以内是否核销。评测指标采用AUC，先对每个优惠券单独计算核销预测的AUC值，再对所有优惠券的AUC值求平均作为最终的评价标准。

## 解决方案概述
赛题提供了两份训练数据和一份测试数据：1. 线下数据集ccf_offline_stage1_train.csv 包含1月到6月用户o2o消费(线上领券到线下消费)、普通线下消费以及线上领券但没有到线下消费的记录； 2. 线上数据集ccf_online_stage1_train.csv 包含1月到6月用户线上消费(网购)的记录; 3. 测试数据集ccf_offline_stage1_test_revised.csv 包含用户7月份领取o2o优惠券的记录，用于预测这些领取的优惠券是否15天内核销。 
从这三份数据集从可以看出: 1、测试集中的用户、商户几乎被线下数据集覆盖; 2. 测试集中的用户只有一小部分被线上数据集覆盖，商户则与线上数据完全没有交集。说明测试数据集和线下数据集是同质的，都是用户进行o2o消费的数据，只不过测试数据集剔除了普通消费记录，而线上数据集虽然数据量很大，但是跟赛题的预测目标关系并不是很大。因此，在进行特征工程的时候，主要精力要放在线下数据集上，线上数据集只能是锦上添花的作用(本人提取的7个线上特征最终的feature importance，不论是rf的还是gbdt的，都很小)。在模型的选择上，使用了random forest、gbdt以及xgboost，auc最高的单模型是random forest。最后将7个auc0.8以上的单模型结果进行集成得到最好的成绩。

## 数据集划分
训练集采用跟测试集相同的时间跨度，即一个月。由于线下数据集中6月份的领券记录截止15号，因此采用滑窗的划分方式，划分为20160516-20160615，20160501-20160531，20160415-20160515，20160401-20160430四份滑窗一个月的用户领券记录。后来又添加了20160601-20160615的半个月跨度的领券记录(虽然时间跨度不一致，但是添加之后auc提高了)。历史特征的提取区间为预测开始日期往前3个月。在提取完特征以后，有一个细节是要对相同User_id,Coupon_id,Date_received的记录进行去重，若有一个核销则记为正例，否则为负例，这是赛题的[FAQ](https://tianchi.aliyun.com/getStart/faq.htm?spm=5176.100067.5678.3.552c254dTwmUuJ&raceId=231593)里的说明。最终5份训练集，调参的时候采用交叉验证，并且确保数据集间的时间顺序，不要出现未来的预测过去的情况。

## 特征工程
特征工程参考了[wepe](https://github.com/wepe/O2O-Coupon-Usage-Forecast)和[ccj_zj](http://blog.csdn.net/ccj_ok/article/details/72675956)两位前辈的特征。分为当月特征和历史特征。当月特征包含了预测区间的用户、商户的领券特征以及优惠券本身的特征，历史特征包含预测开始日期前3个月的用户、商户的领券、核销以及消费的特征。在特征提取过程中出现的缺失值全部填的-1。下面是具体的特征：

- **用户线下历史区间特征**
  
  - 用户领取优惠券次数
  - 用户领取优惠券并15天内核销次数
  - 用户总消费次数
  - 用户核销优惠券中的最小/最大/平均距离
  - 用户从领券到消费的最小/最大/平均时间间隔
  - 用户核销过优惠券的不同商家数量
  - 用户核销过的不同优惠券数量
  - 用户使用优惠券消费占总消费的比例
  - 用户优惠券核销率
  - 用户领取优惠券但没有消费次数
  - 用户核销优惠券的最低/最高/平均折率
  - 用户核销过优惠券的不同商家数量占领取过的不同商家的比重
  - 用户核销过的不同优惠券数量占领取过的不同优惠券的比重
  - 用户平均核销每个商家多少张优惠券
  - 用户平均每种优惠券核销多少张

- **商家历史区间特征**
  - 商家发放优惠券次数
  - 商家发放优惠券15天内被使用次数
  - 商家被消费次数
  - 商家被核销优惠券中的最小/最大/平均距离
  - 商家从被领取到消费的最小/最大/平均时间间隔
  - 核销商家优惠券的不同用户数量
  - 商家被核销过的不同优惠券数量
  - 商家被使用优惠券消费占总消费的比例
  - 商家优惠券核销率
  - 商家优惠券被领取后不核销次数
  - 商家优惠券核销的最低/最高/平均折率
  - 核销商家优惠券的不同用户数量占领取的不同用户数量的比重
  - 商家优惠券平均每个用户核销多少张
  - 商家被核销过的不同优惠券数量占所有领取过的不同优惠券数量的比重
  - 商家平均每种优惠券核销多少张

- **用户-商家历史区间交互特征**
  - 用户在商家领取优惠券次数
  - 用户在商家15天内使用优惠券消费次数
  - 用户在商家总消费次数
  - 用户在商家使用优惠券消费占总消费的比例  - 用户在商家的优惠券核销率
  - 用户领取商家优惠券后不核销次数
  - 用户对每个商家的不核销次数占用户总的不核销次数的比重
  - 用户对每个商家的优惠券核销次数占用户总的核销次数的比重
  - 用户对每个商家的不核销次数占商家总的不核销次数的比重
  - 用户对每个商家的优惠券核销次数占商家总的核销次数的比重

- **用户线上历史区间特征**
  - 用户线上特价消费次数
  - 用户线上普通消费次数
  - 用户线上使用消费券消费次数
  - 用户线上领取优惠券次数
  - 用户线上使用优惠券次数除以领券次数
  - 用户线上使用优惠券次数除以普通消费次数
  - 用户线上特价消费次数除以普通消费次数

- **优惠券历史区间特征**  - 历史出现次数
  - 历史核销次数
  - 历史核销率
  - 历史上用户领取该优惠券次数
  - 历史上用户消费该优惠券次数
  - 历史上用户对该优惠券的核销率
 
- **预测区间特征**
  - 用户领取的所有优惠券数目
  - 用户领取的特定优惠券数目
  - 用户此次之前领取的所有优惠券数目
  - 用户此次之后领取的所有优惠券数目
  - 用户上一次领取优惠券的时间间隔
  - 用户下一次领取优惠券的时间间隔
  - 用户领取特定商家的优惠券数目
  - 用户领取的不同商家数目
  - 用户当天领取的优惠券数目
  - 用户当天领取的特定优惠券数目
  - 用户领取的所有优惠券种类数目
  - 商家被领取的优惠券数目
  - 商家被领取的特定优惠券数目
  - 商家被多少不同用户领取的数目
  - 商家发行的所有优惠券种类数目
  - 用户此次之前领取特定优惠券数目
  - 用户此次之后领取特定优惠券数目

- **当前优惠券特征**
  - 领取优惠券日期是星期几
  - 领取优惠券日期是一个月第几天
  - 商户与用户的距离
  - 满减类优惠券满多少元
  - 优惠券折率
  - 优惠券类型(0-打折 1-满减)

## 调参经验
基于决策树的集成模型(随机森林、GBDT、XGBOOST)的模型参数分为两类：1. 决策树本身的参数，比如max_depth, max_features, min_samples_leaf等，这些参数控制决策树复杂度，太复杂容易过拟合。2. 用于集成的参数，比如n_estimators，GBDT的learning_rate, sub_sample, XGBOOST就更多了eta,gamma,min_child_weight等等。还有其他一些参数比如criterion，class_weight等等。我的经验是对于范围比较大的参数，调参的时候千万不要暴力搜索，什么grid_search之类的太费时间了。采用坐标上升的方法先去调几个主要的参数，比如随机森林，把n_estimators先设置成比较小的数(比如50)以加快训练时间，然后去调max_depth, max_features, min_samples_leaf这三个参数，一次调一个参数，找到最优的以后调下一个，这样迭代的调几次就行了。调完这些取值比较灵活的参数后，再去调criterion，class_weight这些取离散值的参数。最后提交结果的时候再把n_estimators设置为一个较大的值(我设置的是500)。其实不论你如何调参，关键还是看你本地的交叉验证的结果与测试数据的结果是否一致，如果差别很大，那本地调参也就没有意义了。

## 模型集成
把提交过的auc比较高的(比如高于0.79的)结果保存起来，可以用于集成一个成绩更好的结果。集成的方法很简单，就是每个模型预测结果取平均值，或者加权平均，给成绩好的模型更多的权重。这里一个值得注意的地方是不同模型预测值的粒度不同，比如随机森林如果设置了class_weight=balanced(训练数据中负例数量远大于正例，大概是10:1，设置成balanced可以给正例更大的权重)，那么模型的预测值会比gbdt或者xgboost的值大很多(虽然都是0-1的概率，但是相对大小差很多)，这样取均值就没有意义了。AUC的好坏与模型输出的概率偏大或偏小无关，只与正例相对于负例的排名有关。因此在集成的时候，首先将模型原始的预测值转换成rank，再归一化到0-1，再去取均值来集成模型。具体做法参考[kaggle esembling guide](https://mlwave.com/kaggle-ensembling-guide/)

## 总结
通过参加这个比赛，首先熟悉了pandas和sklearn这两个库的使用。其次，在解决问题的过程中，从问题场景的了解，原始数据的探索，到特征的提取，数据的划分，再到模型的调参，深刻了解了机器学习实践中各个步骤的重要性。其实参加这个比赛完全没必要去关注那个排行榜，因为赛题的测试集是固定的，当你平凡地为了提高排名去提交结果的时候，你的模型很可能已经对测试集过拟合了。所以，重点还在对用机器学习解决实际问题的整个流程有一个全面的了解。
